{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7996cb50",
   "metadata": {},
   "source": [
    "# ChatBot AI Agent with LangChain and OpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41cb1027",
   "metadata": {},
   "source": [
    "### Install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c08333e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python3 -m pip install openai==1.55.2 # from terminal or jupyter notebook\n",
    "# !python3 -m pip install langchain==0.3.9 --user # latest as of Nov 2024\n",
    "# pip install langchain-openai==0.2.10\n",
    "# pip install -U langchain-pinecone==0.2.0 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f58f5c1d",
   "metadata": {},
   "source": [
    "### Data Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e2a9ef07",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "996f9b6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI API Key exists and begins sk-proj-\n"
     ]
    }
   ],
   "source": [
    "# Load environment variables in a file called .env\n",
    "# Print the key prefixes to help with any debugging\n",
    "\n",
    "load_dotenv(override=True)\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "if openai_api_key:\n",
    "    print(f\"OpenAI API Key exists and begins {openai_api_key[:8]}\")\n",
    "else:\n",
    "    print(\"OpenAI API Key not set\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "86ad2e93",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\VENOEN\\Pinecone5\\pc5_env\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18891, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>context</th>\n",
       "      <th>question</th>\n",
       "      <th>answers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5733be284776f41900661182</td>\n",
       "      <td>University_of_Notre_Dame</td>\n",
       "      <td>Architecturally, the school has a Catholic cha...</td>\n",
       "      <td>To whom did the Virgin Mary allegedly appear i...</td>\n",
       "      <td>{'text': ['Saint Bernadette Soubirous'], 'answ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5733bf84d058e614000b61be</td>\n",
       "      <td>University_of_Notre_Dame</td>\n",
       "      <td>As at most other universities, Notre Dame's st...</td>\n",
       "      <td>When did the Scholastic Magazine of Notre dame...</td>\n",
       "      <td>{'text': ['September 1876'], 'answer_start': [...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         id                     title  \\\n",
       "0  5733be284776f41900661182  University_of_Notre_Dame   \n",
       "5  5733bf84d058e614000b61be  University_of_Notre_Dame   \n",
       "\n",
       "                                             context  \\\n",
       "0  Architecturally, the school has a Catholic cha...   \n",
       "5  As at most other universities, Notre Dame's st...   \n",
       "\n",
       "                                            question  \\\n",
       "0  To whom did the Virgin Mary allegedly appear i...   \n",
       "5  When did the Scholastic Magazine of Notre dame...   \n",
       "\n",
       "                                             answers  \n",
       "0  {'text': ['Saint Bernadette Soubirous'], 'answ...  \n",
       "5  {'text': ['September 1876'], 'answer_start': [...  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://rajpurkar.github.io/SQuAD-explorer/\n",
    "\n",
    "from datasets import load_dataset \n",
    "\n",
    "data = load_dataset('squad', split='train')\n",
    "df = data.to_pandas()\n",
    "df.drop_duplicates(subset='context', keep='first', inplace=True)\n",
    "print(df.shape)\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6609861a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = data.to_pandas()\n",
    "# df.iloc[0]['context']\n",
    "# df.iloc[0]['question']\n",
    "# df.iloc[0]['answers']\n",
    "# sum(df['context'].duplicated())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d24be300",
   "metadata": {},
   "source": [
    "### Embedding API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bb69c1d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This block is older code using openai==0.28. \n",
    "# You can still use it but make sure to install : pip install openai==0.28\n",
    "\n",
    "# openai.api_key = OPENAI_API_KEY\n",
    "# MODEL  = \"text-embedding-ada-002\"\n",
    "\n",
    "# res = openai.Embedding.create(input = \"I love openai\", engine = MODEL) \n",
    "# embedding = response['data'][0]['embedding']\n",
    "# print(embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a7261cc7-fa25-49ff-b834-812d96f7b7bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This block uses lates (Nov 2024) version of openai : # openai.__version__  #'1.55.2'\n",
    "from openai import OpenAI\n",
    "import os\n",
    "\n",
    "MODEL = \"text-embedding-ada-002\"\n",
    "\n",
    "client = OpenAI(api_key=os.environ.get(\"OPENAI_API_KEY\", openai_api_key)) # first one will work if set as env var, second one explicit one\n",
    "\n",
    "response = client.embeddings.create(\n",
    "    input=\"I love openai\",\n",
    "    model=MODEL\n",
    ")\n",
    "\n",
    "# usage\n",
    "embedding  = (response.data)[0].embedding # new code for v-1.55.2\n",
    "# print(embedding)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c171b404",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "required vector dim: 1536\n"
     ]
    }
   ],
   "source": [
    "# helper function\n",
    "def get_embedding(text, model):\n",
    "    text = text.replace(\"\\n\", \" \")\n",
    "    res = client.embeddings.create(input = text, model = model) # engine replaced by model in v-1.55.2\n",
    "    return (response.data)[0].embedding\n",
    "\n",
    "vec = get_embedding(\"I am trying a new text \\n And see what happens\", MODEL)\n",
    "print(f\"required vector dim: {len(vec)}\") # dimension of the index\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d19a1a70",
   "metadata": {},
   "source": [
    "### Vector DB Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e11dc81",
   "metadata": {},
   "outputs": [],
   "source": [
    "pc_api_key = os.getenv('PINECONE_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73a5a90e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# db of 1536 dimension\n",
    "\n",
    "from pinecone import Pinecone, ServerlessSpec\n",
    "# API_KEY = \"YOUR API KEY\"\n",
    "pc = Pinecone(api_key = pc_api_key)\n",
    "\n",
    "# pc.create_index(\"ai-agent\", dimension=1536, metric='dotproduct',\n",
    "#                      spec=ServerlessSpec(cloud=\"aws\", region=\"us-east-1\"))\n",
    "index = pc.Index(\"ai-agent\")\n",
    "# index.delete(delete_all=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cea5732",
   "metadata": {},
   "source": [
    "### Indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "212b20ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sample = df.sample(1000, random_state=45)\n",
    "batch_size = 100 # free tier limit 20 RPM in 2023 now 3000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1f68b7b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# embedding function from OpenAI, old code  won't work anymore. instead use langchain-openai as shown in next cell\n",
    "# from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "\n",
    "# model_name = \"text-embedding-ada-002\"\n",
    "\n",
    "# embed = OpenAIEmbeddings(\n",
    "#     model = model_name,\n",
    "#     openai_api_key= OPENAI_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1928fab6-e608-4851-be77-42a88d092a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://pypi.org/project/langchain-openai/\n",
    "# pip install langchain-openai==0.2.10\n",
    "\n",
    "from langchain_openai import OpenAIEmbeddings \n",
    "\n",
    "MODEL = \"text-embedding-ada-002\"\n",
    "embed = OpenAIEmbeddings(\n",
    "    model = MODEL,\n",
    "    openai_api_key= OPENAI_API_KEY)\n",
    "\n",
    "# Usage:\n",
    "# doc1 = \"Hello how are you\"\n",
    "# doc2 = \"Hello everyone!\"\n",
    "# embed.embed_query(doc) # single doc\n",
    "# embed.embed_documents([doc1, doc2])  # output will be list of list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "487040ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "02c73fa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [00:26<00:00,  2.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 3.48 s\n",
      "Wall time: 26.6 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for i in tqdm(range(0, len(df_sample), batch_size)):\n",
    "    i_end = min(i+batch_size, len(df_sample))\n",
    "#     print(i, i_end)\n",
    "    batch = df_sample.iloc[i:i_end]\n",
    "    meta_data = [{\"titile\" : row['title'], \n",
    "              \"context\": row['context']} \n",
    "             for i, row in batch.iterrows()]\n",
    "    \n",
    "    # embedding  \n",
    "    docs = batch['context'].tolist()  # pd.Series to python list\n",
    "#     emb_vectors = [get_embedding(doc, MODEL) for doc in docs] \n",
    "    emb_vectors = embed.embed_documents(docs) # list of list\n",
    "\n",
    "    ids = batch['id'].tolist()\n",
    "    \n",
    "    # upsert\n",
    "    to_upsert = zip(ids, emb_vectors, meta_data)    \n",
    "    index.upsert(vectors=to_upsert)\n",
    "    \n",
    "    # time.sleep(20) # 8s for 50 data points, this was needed when free tier had rate limit to 20RPM, no need anymore\n",
    "\n",
    "    \n",
    "# df.shape[0]/3600 # 5 hrs to load , free tier will take 15hrs\n",
    "# # 14000 records/dollar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50a4c889",
   "metadata": {},
   "source": [
    "### Using"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "871f8cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embedding2(text):\n",
    "    text = text.replace(\"\\n\", \" \")\n",
    "    res = client.embeddings.create(input = text, \n",
    "                                  model = \"text-embedding-ada-002\")\n",
    "    return (res.data)[0].embedding\n",
    "\n",
    "# get_embedding2(\"tabula rasa\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "c90a0427-459d-4b1c-bcef-9b0efccbdbcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Updated code with new libraries and classes\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "from langchain_openai import OpenAIEmbeddings \n",
    "\n",
    "MODEL = \"text-embedding-ada-002\"\n",
    "\n",
    "# Initialize the vector store with the correct embedding method\n",
    "embeddings = OpenAIEmbeddings(model=MODEL, api_key=OPENAI_API_KEY)\n",
    "\n",
    "\n",
    "vectorstore = PineconeVectorStore(index, embeddings, \"context\", pinecone_api_key= API_KEY) # df['context'] column is the actual text field to search from\n",
    "\n",
    "# Perform the similarity search, pure semantic, nothing genrative\n",
    "query = \"destruction of US fifth fleet\"\n",
    "results = vectorstore.similarity_search(query, k=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "30e3945f-96ac-4399-8fc1-a2514fbb94bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='573228eab9d445190005e86f', metadata={'titile': 'Pacific_War'}, page_content=\"It was imperative for Japanese commanders to hold Saipan. The only way to do this was to destroy the U.S. Fifth Fleet, which had 15 fleet carriers and 956 planes, 7 battleships, 28 submarines, and 69 destroyers, as well as several light and heavy cruisers. Vice Admiral Jisaburo Ozawa attacked with nine-tenths of Japan's fighting fleet, which included nine carriers with 473 planes, 5 battleships, several cruisers, and 28 destroyers. Ozawa's pilots were outnumbered 2:1 and their aircraft were becoming or were already obsolete. The Japanese had considerable antiaircraft defenses but lacked proximity fuzes or good radar. With the odds against him, Ozawa devised an appropriate strategy. His planes had greater range because they were not weighed down with protective armor; they could attack at about 480 km (300 mi)[citation needed], and could search a radius of 900 km[citation needed] (560 mi). U.S. Navy Hellcat fighters could only attack within 200 miles (320 km) and only search within a 325-mile (523 km)[citation needed] radius. Ozawa planned to use this advantage by positioning his fleet 300 miles (480 km)[citation needed] out. The Japanese planes would hit the U.S. carriers, land at Guam to refuel, then hit the enemy again when returning to their carriers. Ozawa also counted on about 500 land-based planes at Guam and other islands.\"),\n",
       " Document(id='57269adedd62a815002e8ad6', metadata={'titile': 'Korean_War'}, page_content='Acting on State Secretary Acheson\\'s recommendation, President Truman ordered General MacArthur to transfer matériel to the Army of the Republic of Korea while giving air cover to the evacuation of U.S. nationals. The President disagreed with advisers who recommended unilateral U.S. bombing of the North Korean forces, and ordered the US Seventh Fleet to protect the Republic of China (Taiwan), whose government asked to fight in Korea. The United States denied ROC\\'s request for combat, lest it provoke a communist Chinese retaliation. Because the United States had sent the Seventh Fleet to \"neutralize\" the Taiwan Strait, Chinese premier Zhou Enlai criticized both the UN and U.S. initiatives as \"armed aggression on Chinese territory.\"')]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3d66dfb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# embed.embed_query(\"embedding single document\")\n",
    "\n",
    "# embed.embed_documents([\"first doc\", \"second doc\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01492f23",
   "metadata": {},
   "source": [
    "### Define QA Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "96085575",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains.conversation.memory \\\n",
    "import ConversationBufferWindowMemory\n",
    "\n",
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "# OpenAI LLM\n",
    "llm = ChatOpenAI(openai_api_key = OPENAI_API_KEY,\n",
    "                model_name = 'gpt-3.5-turbo',\n",
    "                temperature = 0.0)\n",
    "\n",
    "# conversational memory\n",
    "conv_mem = ConversationBufferWindowMemory(\n",
    "    memory_key = 'chat_history',\n",
    "    k = 5,\n",
    "    return_messages =True)\n",
    "\n",
    "# retrieval qa\n",
    "qa = RetrievalQA.from_chain_type(\n",
    "    llm = llm,\n",
    "    chain_type = \"stuff\",\n",
    "    retriever = vectorstore.as_retriever())\n",
    "\n",
    "\n",
    "# https://python.langchain.com/en/latest/modules/chains/index_examples/question_answering.html\n",
    "# https://docs.langchain.com/docs/components/chains/index_related_chains"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba438491",
   "metadata": {},
   "source": [
    "### Invoking Retrieval QA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "08f8c03c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': 'Which year university of notredame was established',\n",
       " 'result': 'The University of Notre Dame du Lac was established in 1842.'}"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"Which year university of notredame was established\"\n",
    "qa.invoke(query) # retrieving the info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "9b76a216",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': 'who established the university of notredame',\n",
       " 'result': 'The University of Notre Dame du Lac was established by Father Edward Sorin, who was a priest of the Congregation of Holy Cross. He founded the university in 1842.'}"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"who established the university of notredame\"\n",
    "qa.invoke(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "cd624c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import Tool\n",
    "\n",
    "tools = [\n",
    "    Tool(\n",
    "    name = 'Knowledge Base',\n",
    "    func = qa.invoke,\n",
    "    description = ('use this when answering based on knwowledge')\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "d0c92f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import initialize_agent\n",
    "from langchain.agents import AgentType\n",
    "\n",
    "agent = initialize_agent(\n",
    "    agent=AgentType.CHAT_CONVERSATIONAL_REACT_DESCRIPTION,\n",
    "    tools=tools,\n",
    "    llm=llm,\n",
    "    verbose=True,\n",
    "    max_iterations=3,\n",
    "    early_stopping_method='generate',\n",
    "    memory=conv_mem \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "65eacac5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m```json\n",
      "{\n",
      "    \"action\": \"Knowledge Base\",\n",
      "    \"action_input\": \"University of Notre Dame establishment date\"\n",
      "}\n",
      "```\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m{'query': 'University of Notre Dame establishment date', 'result': 'The University of Notre Dame du Lac was founded on November 26, 1842.'}\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m```json\n",
      "{\n",
      "    \"action\": \"Final Answer\",\n",
      "    \"action_input\": \"The University of Notre Dame du Lac was founded on November 26, 1842.\"\n",
      "}\n",
      "```\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'when was university of notredame established',\n",
       " 'chat_history': [],\n",
       " 'output': 'The University of Notre Dame du Lac was founded on November 26, 1842.'}"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent(\"when was university of notredame established\") # chat gpt kind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "e8cb7fe4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m```json\n",
      "{\n",
      "    \"action\": \"Knowledge Base\",\n",
      "    \"action_input\": \"University of Notre Dame du Lac was founded by Rev. Edward Sorin, C.S.C., who was a priest of the Congregation of Holy Cross.\"\n",
      "}\n",
      "```\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m{'query': 'University of Notre Dame du Lac was founded by Rev. Edward Sorin, C.S.C., who was a priest of the Congregation of Holy Cross.', 'result': 'Yes, that is correct. Rev. Edward Sorin, C.S.C., a priest of the Congregation of Holy Cross, founded the University of Notre Dame du Lac in 1842.'}\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m```json\n",
      "{\n",
      "    \"action\": \"Final Answer\",\n",
      "    \"action_input\": \"Rev. Edward Sorin, C.S.C., a priest of the Congregation of Holy Cross, founded the University of Notre Dame du Lac in 1842.\"\n",
      "}\n",
      "```\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'who founded the university',\n",
       " 'chat_history': [HumanMessage(content='when was university of notredame established', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='The University of Notre Dame du Lac was founded on November 26, 1842.', additional_kwargs={}, response_metadata={})],\n",
       " 'output': 'Rev. Edward Sorin, C.S.C., a priest of the Congregation of Holy Cross, founded the University of Notre Dame du Lac in 1842.'}"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent(\"who founded the university\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "a3d77137",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m```json\n",
      "{\n",
      "    \"action\": \"Final Answer\",\n",
      "    \"action_input\": \"26\"\n",
      "}\n",
      "```\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': '20+6',\n",
       " 'chat_history': [HumanMessage(content='when was university of notredame established', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='The University of Notre Dame du Lac was founded on November 26, 1842.', additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content='who founded the university', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='Rev. Edward Sorin, C.S.C., a priest of the Congregation of Holy Cross, founded the University of Notre Dame du Lac in 1842.', additional_kwargs={}, response_metadata={})],\n",
       " 'output': '26'}"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent(\"20+6\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3aa0f50",
   "metadata": {},
   "source": [
    "#### Note on the Rate Limit\n",
    "\n",
    "Rate Limit: https://github.com/openai/openai-cookbook/blob/main/examples/How_to_handle_rate_limits.ipynb\n",
    "\n",
    "Retry Options: https://github.com/openai/openai-cookbook/blob/main/examples/How_to_handle_rate_limits.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6eb8a0a",
   "metadata": {},
   "source": [
    "### Further Reading\n",
    "\n",
    "https://arxiv.org/abs/2005.11401 \n",
    "\n",
    "https://platform.openai.com/docs/models/gpt-3-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7da8e37",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Venv_llm_eng_3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
